{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration Examples: Combining Multiple Metrics with Monet Stats\n",
    "\n",
    "This notebook demonstrates comprehensive analysis workflows that combine multiple metrics from different categories for holistic model evaluation in atmospheric sciences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import monet_stats as ms\n",
    "\n",
    "# For xarray support\n",
    "import xarray as xr\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Multiple Datasets\n",
    "\n",
    "Load the example datasets and prepare them for comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all example datasets\n",
    "print(\"Loading example datasets for comprehensive analysis...\")\n",
    "\n",
    "try:\n",
    "    temp_df = pd.read_csv('../data/temperature_obs_mod.csv')\n",
    "    precip_df = pd.read_csv('../data/precipitation_obs_mod.csv')\n",
    "    wind_df = pd.read_csv('../data/wind_obs_mod.csv')\n",
    "    obs_da = xr.open_dataset('../data/spatial_obs.nc')['observed_temp']\n",
    "    mod_da = xr.open_dataset('../data/spatial_mod.nc')['modeled_temp']\n",
    "    \n",
    "    print(\"All datasets loaded successfully!\")\n",
    "    print(f\"Temperature: {temp_df.shape[0]} records\")\n",
    "    print(f\"Precipitation: {precip_df.shape[0]} records\")\n",
    "    print(f\"Wind: {wind_df.shape[0]} records\")\n",
    "    print(f\"Spatial: {obs_da.shape[0]} time steps, {obs_da.shape[1]} x {obs_da.shape[2]} grid\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    # Generate synthetic data if files don't exist\n",
    "    print(\"Generating synthetic datasets...\")\n",
    "    \n",
    "    # Generate synthetic temperature data\n",
    "    n_samples = 1000\n",
    "    temp_df = pd.DataFrame({\n",
    "        'observed_temp': np.random.normal(15, 5, n_samples),\n",
    "        'modeled_temp': np.random.normal(14.5, 5.2, n_samples),\n",
    "        'station_id': ['STN001'] * n_samples\n",
    "    })\n",
    "    \n",
    "    # Generate synthetic precipitation data\n",
    "    precip_df = pd.DataFrame({\n",
    "        'observed_precip': np.random.gamma(0.5, 2, n_samples),\n",
    "        'modeled_precip': np.random.gamma(0.6, 2.1, n_samples),\n",
    "        'obs_binary_precip': (np.random.gamma(0.5, 2, n_samples) > 0.1).astype(int),\n",
    "        'mod_binary_precip': (np.random.gamma(0.6, 2.1, n_samples) > 0.1).astype(int),\n",
    "        'station_id': ['STN001'] * n_samples\n",
    "    })\n",
    "    \n",
    "    # Generate synthetic wind data\n",
    "    wind_df = pd.DataFrame({\n",
    "        'observed_wind_speed': np.random.lognormal(1.5, 0.5, n_samples),\n",
    "        'modeled_wind_speed': np.random.lognormal(1.4, 0.6, n_samples),\n",
    "        'observed_wind_dir': np.random.uniform(0, 360, n_samples),\n",
    "        'modeled_wind_dir': np.random.uniform(10, 370, n_samples),\n",
    "        'station_id': ['STN001'] * n_samples\n",
    "    })\n",
    "    \n",
    "    # Generate synthetic spatial data\n",
    "    obs_da = xr.DataArray(\n",
    "        np.random.normal(15, 5, (10, 20, 20)),\n",
    "        dims=['time', 'lat', 'lon'],\n",
    "        coords={'time': pd.date_range('2020-01-01', periods=10), 'lat': np.linspace(30, 50, 20), 'lon': np.linspace(-120, -70, 20)}\n",
    "    )\n",
    "    mod_da = xr.DataArray(\n",
    "        np.random.normal(14.5, 5.2, (10, 20, 20)),\n",
    "        dims=['time', 'lat', 'lon'],\n",
    "        coords={'time': pd.date_range('2020-01-01', periods=10), 'lat': np.linspace(30, 50, 20), 'lon': np.linspace(-120, -70, 20)}\n",
    "    )\n",
    "\n",
    "# Prepare combined dataset\n",
    "print(\"\\nCombining datasets for comprehensive analysis...\")\n",
    "\n",
    "# Calculate metrics for each dataset\n",
    "def calculate_metrics(obs, mod, dataset_name):\n",
    "    \"\"Calculate comprehensive metrics for a dataset\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Ensure arrays are numpy arrays\n",
    "    obs_array = np.array(obs)\n",
    "    mod_array = np.array(mod)\n",
    "    \n",
    "    # Remove NaN values\n",
    "    valid_mask = ~(np.isnan(obs_array) | np.isnan(mod_array))\n",
    "    obs_valid = obs_array[valid_mask]\n",
    "    mod_valid = mod_array[valid_mask]\n",
    "    \n",
    "    if len(obs_valid) > 0:\n",
    "        metrics['dataset'] = dataset_name\n",
    "        metrics['n_samples'] = len(obs_valid)\n",
    "        \n",
    "        # Error metrics\n",
    "        metrics['MAE'] = ms.MAE(obs_valid, mod_valid)\n",
    "        metrics['RMSE'] = ms.RMSE(obs_valid, mod_valid)\n",
    "        metrics['MBE'] = ms.MBE(obs_valid, mod_valid)\n",
    "        metrics['MAPE'] = ms.MAPE(obs_valid, mod_valid)\n",
    "        metrics['MPE'] = ms.MPE(obs_valid, mod_valid)\n",
    "        \n",
    "        # Correlation metrics\n",
    "        metrics['Pearson'] = ms.pearson_correlation(obs_valid, mod_valid)\n",
    "        metrics['Spearman'] = ms.spearman_correlation(obs_valid, mod_valid)\n",
    "        metrics['R2'] = ms.R2(obs_valid, mod_valid)\n",
    "        \n",
    "        # Skill scores\n",
    "        metrics['NSE'] = ms.NSE(obs_valid, mod_valid)\n",
    "        metrics['mNSE'] = ms.mNSE(obs_valid, mod_valid)\n",
    "        metrics['rNSE'] = ms.rNSE(obs_valid, mod_valid)\n",
    "        metrics['NSEm'] = ms.NSEm(obs_valid, mod_valid)\n",
    "        \n",
    "        # Calculate skill score\n",
    "        climatology = np.mean(obs_valid)\n",
    "        rmse_model = metrics['RMSE']\n",
    "        rmse_clim = ms.RMSE(obs_valid, np.full_like(obs_valid, climatology))\n",
    "        metrics['SS'] = ms.SS(mse_model=rmse_model**2, mse_reference=rmse_clim**2)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for each dataset\n",
    "temp_metrics = calculate_metrics(temp_df['observed_temp'], temp_df['modeled_temp'], 'Temperature')\n",
    "precip_metrics = calculate_metrics(precip_df['observed_precip'], precip_df['modeled_precip'], 'Precipitation')\n",
    "wind_metrics = calculate_metrics(wind_df['observed_wind_speed'], wind_df['modeled_wind_speed'], 'Wind Speed')\n",
    "\n",
    "# Calculate spatial metrics for first time step\n",
    "obs_spatial = obs_da[0, :, :].values.flatten()\n",
    "mod_spatial = mod_da[0, :, :].values.flatten()\n",
    "spatial_metrics = calculate_metrics(obs_spatial, mod_spatial, 'Spatial')\n",
    "\n",
    "# Combine all metrics\n",
    "all_metrics = [temp_metrics, precip_metrics, wind_metrics, spatial_metrics]\n",
    "metrics_df = pd.DataFrame([m for m in all_metrics if m])  # Remove empty metrics\n",
    "\n",
    "print(f\"\\nCalculated metrics for {len(metrics_df)} datasets:\")\n",
    "print(metrics_df[['dataset', 'n_samples', 'MAE', 'RMSE', 'Pearson', 'R2', 'NSE', 'SS']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Dataset Performance Comparison\n",
    "\n",
    "Compare model performance across different datasets and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance comparison\n",
    "print(\"Multi-Dataset Performance Analysis:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Performance radar chart\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Radar chart for error metrics\n",
    "categories = ['MAE', 'RMSE', 'MBE']\n",
    "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)\n",
    "angles = np.concatenate((angles, [angles[0]]))  # Complete the circle\n",
    "\n",
    "# Normalize metrics for radar chart (lower is better)\n",
    "error_metrics = ['MAE', 'RMSE', 'MBE']\n",
    "normalized_metrics = metrics_df[error_metrics].copy()\n",
    "for metric in error_metrics:\n",
    "    normalized_metrics[metric] = normalized_metrics[metric] / normalized_metrics[metric].max()\n",
    "\n",
    "# Plot radar chart\n",
    "ax = axes[0, 0]\n",
    "for idx, row in normalized_metrics.iterrows():\n",
    "    values = row[error_metrics].values.tolist()\n",
    "    values.append(values[0])  # Complete the circle\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=row['dataset'])\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Error Metrics (Normalized, Lower is Better)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bar chart for correlation metrics\n",
    "corr_metrics = ['Pearson', 'Spearman', 'R2']\n",
    "x = np.arange(len(metrics_df))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(corr_metrics):\n",
    "    if metric in metrics_df.columns:\n",
    "        axes[0, 1].bar(x + i * width, metrics_df[metric], width, label=metric)\n",
    "\n",
    "axes[0, 1].set_xlabel('Dataset')\n",
    "axes[0, 1].set_ylabel('Correlation Value')\n",
    "axes[0, 1].set_title('Correlation Metrics by Dataset')\n",
    "axes[0, 1].set_xticks(x + width)\n",
    "axes[0, 1].set_xticklabels(metrics_df['dataset'], rotation=45)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Skill scores comparison\n",
    "skill_metrics = ['NSE', 'SS']\n",
    "x_skill = np.arange(len(metrics_df))\n",
    "\n",
    "for i, metric in enumerate(skill_metrics):\n",
    "    if metric in metrics_df.columns:\n",
    "        axes[1, 0].bar(x_skill + i * width, metrics_df[metric], width, label=metric)\n",
    "\n",
    "axes[1, 0].set_xlabel('Dataset')\n",
    "axes[1, 0].set_ylabel('Skill Score')\n",
    "axes[1, 0].set_title('Skill Scores by Dataset')\n",
    "axes[1, 0].set_xticks(x_skill + width)\n",
    "axes[1, 0].set_xticklabels(metrics_df['dataset'], rotation=45)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Performance ranking\n",
    "# Create composite performance score\n",
    "performance_score = pd.DataFrame()\n",
    "performance_score['dataset'] = metrics_df['dataset']\n",
    "performance_score['n_samples'] = metrics_df['n_samples']\n",
    "\n",
    "# Calculate composite score (higher is better)\n",
    "performance_score['composite_score'] = (\n",
    "    metrics_df['Pearson'] * 0.3 +\n",
    "    metrics_df['R2'] * 0.2 +\n",
    "    metrics_df['NSE'] * 0.2 +\n",
    "    metrics_df['SS'] * 0.2 +\n",
    "    (1 - metrics_df['RMSE'] / metrics_df['RMSE'].max()) * 0.1\n",
    ")\n",
    "\n",
    "# Sort by composite score\n",
    "performance_score = performance_score.sort_values('composite_score', ascending=False)\n",
    "\n",
    # Plot performance ranking\n",
    "axes[1, 1].barh(range(len(performance_score)), performance_score['composite_score'])\n",
    "axes[1, 1].set_yticks(range(len(performance_score)))\n",
    "axes[1, 1].set_yticklabels(performance_score['dataset'])\n",
    "axes[1, 1].set_xlabel('Composite Performance Score')\n",
    "axes[1, 1].set_title('Overall Performance Ranking')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add score values\n",
    "for i, score in enumerate(performance_score['composite_score']):\n",
    "    axes[1, 1].text(score + 0.01, i, f'{score:.3f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    print(\"\\nPerformance Ranking and Summary:\")\n",
    print(performance_score.round(4))"
   ]
 },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Statistical Analysis Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive statistical analysis workflow\n",
    "print(\"Combined Statistical Analysis Workflow:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Function for comprehensive analysis\n",
    "def comprehensive_analysis(obs, mod, dataset_name):\n",
    "    \"\"Perform comprehensive statistical analysis\"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    obs_array = np.array(obs)\n",
    "    mod_array = np.array(mod)\n",
    "    \n",
    "    # Remove NaN values\n",
    "    valid_mask = ~(np.isnan(obs_array) | np.isnan(mod_array))\n",
    "    obs_valid = obs_array[valid_mask]\n",
    "    mod_valid = mod_array[valid_mask]\n",
    "\n",
    "    if len(obs_valid) == 0:\n",
    "        return None\n",
    "\n",
    "    # Calculate all available metrics\n",
    "    analysis_results = {\n",
    "        'dataset': dataset_name,\n",
    "        'basic_stats': {\n",
    "            'n_samples': len(obs_valid),\n",
    "            'obs_mean': np.mean(obs_valid),\n",
    "            'obs_std': np.std(obs_valid),\n",
    "            'mod_mean': np.mean(mod_valid),\n",
    "            'mod_std': np.std(mod_valid)\n",
    "        },\n",
    "        'error_metrics': {\n",
    "            'MAE': ms.MAE(obs_valid, mod_valid),\n",
    "            'RMSE': ms.RMSE(obs_valid, mod_valid),\n",
    "            'MBE': ms.MBE(obs_valid, mod_valid),\n",
    "            'MAPE': ms.MAPE(obs_valid, mod_valid),\n",
    "            'MPE': ms.MPE(obs_valid, mod_valid)\n",
    "        },\n",
    "        'correlation_metrics': {\n",
    "            'Pearson': ms.pearson_correlation(obs_valid, mod_valid),\n",
    "            'Spearman': ms.spearman_correlation(obs_valid, mod_valid),\n",
    "            'R2': ms.R2(obs_valid, mod_valid)\n",
    "        },\n",
    "        'skill_scores': {\n",
    "            'NSE': ms.NSE(obs_valid, mod_valid),\n",
    "            'mNSE': ms.mNSE(obs_valid, mod_valid),\n",
    "            'rNSE': ms.rNSE(obs_valid, mod_valid),\n",
    "            'NSEm': ms.NSEm(obs_valid, mod_valid)\n",
    "        },\n",
    "        'analysis': {\n",
    "            'bias_ratio': np.mean(mod_valid) / np.mean(obs_valid),\n",
    "            'spread_ratio': np.std(mod_valid) / np.std(obs_valid),\n",
    "            'rmse_skill': calculate_rmse_skill(obs_valid, mod_valid)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return analysis_results\n",
    "\n",
    "# Helper function for RMSE skill\n",
    "def calculate_rmse_skill(obs, mod):\n",
    "    \"\"Calculate RMSE skill score\"\"\"\n",
    "    climatology = np.mean(obs)\n",
    "    rmse_model = ms.RMSE(obs, mod)\n",
    "    rmse_clim = ms.RMSE(obs, np.full_like(obs, climatology))\n",
    "    return ms.SS(mse_model=rmse_model**2, mse_reference=rmse_clim**2)\n",
    "\n",
    "# Perform comprehensive analysis on all datasets\n",
    "comprehensive_results = {}\n",
    "\n",
    datasets = {\n",
    "    'Temperature': (temp_df['observed_temp'], temp_df['modeled_temp']),\n",
    "    'Precipitation': (precip_df['observed_precip'], precip_df['modeled_precip']),\n",
    "    'Wind Speed': (wind_df['observed_wind_speed'], wind_df['modeled_wind_speed']),\n",
    "    'Spatial': (obs_spatial, mod_spatial)\n",
    "}\n",
    "\n",
    "for name, (obs, mod) in datasets.items():\n",
    "    comprehensive_results[name] = comprehensive_analysis(obs, mod, name)\n",
    "\n",
    "# Display comprehensive results\n",
    "print(\"\\nComprehensive Analysis Results:\")\n",
    "for name, results in comprehensive_results.items():\n",
    "    if results:\n",
    "        print(f\"\\n{name} Analysis:\")\n",
    "        print(f\"Basic Stats: {results['basic_stats']}\")\n",
    "        print(f\"Error Metrics: {results['error_metrics']}\")\n",
    "        print(f\"Correlation: {results['correlation_metrics']}\")\n",
    "        print(f\"Skill Scores: {results['skill_scores']}\")\n",
    "        print(f\"Diagnostic Analysis: {results['analysis']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Integration\n",
    "\n",
    "Use machine learning to identify patterns in model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# Create machine learning integration for model evaluation\n",
    "print(\"Machine Learning Integration for Model Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prepare feature matrix from metrics\n",
    "feature_data = []\n",
    "for name, results in comprehensive_results.items():\n",
    "    if results:\n",
    "        features = [\n",
    "            results['error_metrics']['MAE'],\n",
    "            results['error_metrics']['RMSE'],\n",
    "            results['error_metrics']['MBE'],\n",
    "            results['correlation_metrics']['Pearson'],\n",
    "            results['correlation_metrics']['R2'],\n",
    "            results['skill_scores']['NSE'],\n",
    "            results['skill_scores']['mNSE'],\n",
    "            results['analysis']['bias_ratio'],\n",
    "            results['analysis']['spread_ratio'],\n",
    "            results['basic_stats']['n_samples']\n",
    "        ]\n",
    "        feature_data.append(features)\n",
    "\n",
    "feature_names = [\n",
    "    'MAE', 'RMSE', 'MBE', 'Pearson', 'R2', 'NSE', 'mNSE', \n",
    "    'Bias_Ratio', 'Spread_Ratio', 'n_samples'\n",
    "]\n",
    "\n",
    "# Create feature matrix\n",
    "X = np.array(feature_data)\n",
    "dataset_names = list(comprehensive_results.keys())\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    print(f\"PCA Explained Variance Ratio: {pca.explained_variance_ratio_}\")\n",
    print(f\"Total Explained Variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# PCA plot\n",
    "axes[0, 0].scatter(X_pca[:, 0], X_pca[:, 1], s=100, alpha=0.7)\n",
    "for i, name in enumerate(dataset_names):\n",
    "    axes[0, 0].annotate(name, (X_pca[i, 0], X_pca[i, 1]), xytext=(5, 5), textcoords='offset points')\n",
    "axes[0, 0].set_xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[0, 0].set_ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "axes[0, 0].set_title('PCA of Model Performance Metrics')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = np.abs(pca.components_[0])  # First principal component\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "axes[0, 1].bar(range(len(feature_importance)), feature_importance[sorted_idx])\n",
    "axes[0, 1].set_xticks(range(len(feature_importance)))\n",
    "axes[0, 1].set_xticklabels([feature_names[i] for i in sorted_idx], rotation=45)\n",
    "axes[0, 1].set_xlabel('Features')\n",
    "axes[0, 1].set_ylabel('Absolute Loading')\n",
    "axes[0, 1].set_title('Feature Importance (PC1)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Clustering analysis\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    # Cluster visualization\n",
    "scatter = axes[1, 0].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', s=100, alpha=0.7)\n",
    "axes[1, 0].set_xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "axes[1, 0].set_ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "axes[1, 0].set_title('K-means Clustering of Datasets')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=axes[1, 0])\n",
    "\n",
    "# Radar chart for feature analysis\n",
    "radar_data = X_scaled.T\n",
    "angles = np.linspace(0, 2 * np.pi, len(feature_names), endpoint=False)\n",
    "angles = np.concatenate((angles, [angles[0]]))\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    values = radar_data[:, i].tolist()\n",
    "    values.append(values[0])\n",
    "    axes[1, 1].plot(angles, values, 'o-', linewidth=2, label=dataset_names[i])\n",
    "    axes[1, 1].fill(angles, values, alpha=0.1)\n",
    "\n",
    "axes[1, 1].set_xticks(angles[:-1])\n",
    "axes[1, 1].set_xticklabels(feature_names, rotation=45)\n",
    "axes[1, 1].set_ylim(-3, 3)\n",
    "axes[1, 1].set_title('Feature Analysis Radar Chart')\n",
    "axes[1, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    print(f\"\\nClustering Results:\")\n",
    "for i, name in enumerate(dataset_names):\n",
    "    print(f\"{name}: Cluster {clusters[i] + 1}\")\n",
    "\n",
    print(f\"\\nCluster Centers:\")\n",
    "cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "for i, center in enumerate(cluster_centers):\n",
    "    print(f\"Cluster {i + 1}: {center[:5].round(3)}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Variable Time Series Analysis\n",
    "\n",
    "Analyze temporal patterns across multiple variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# Create multi-variable time series analysis\n",
    "print(\"Multi-Variable Time Series Analysis:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Generate synthetic time series data for demonstration\n",
    "n_time_steps = 365  # One year\n",
    "time = pd.date_range('2020-01-01', periods=n_time_steps, freq='D')\n",
    "\n",
    "# Generate correlated time series\n",
    "np.random.seed(42)\n",
    "temp_base = 15 + 10 * np.sin(2 * np.pi * np.arange(n_time_steps) / 365.25)\n",
    "precip_base = np.random.gamma(0.5, 2, n_time_steps)\n",
    "wind_base = 5 + 3 * np.sin(2 * np.pi * np.arange(n_time_steps) / 365.25 + np.pi/4)\n",
    "\n",
    "# Create model data with biases\n",
    "temp_obs = temp_base + np.random.normal(0, 1, n_time_steps)\n",
    "temp_mod = temp_obs - 0.5 + np.random.normal(0, 1.2, n_time_steps)\n",
    "\n",
    "precip_obs = precip_base\n",
    "precip_mod = precip_base * 1.1 + np.random.exponential(0.5, n_time_steps)\n",
    "\n",
    "wind_obs = wind_base + np.random.normal(0, 0.5, n_time_steps)\n",
    "wind_mod = wind_obs + 0.2 + np.random.normal(0, 0.7, n_time_steps)\n",
    "\n",
    "# Create time series DataFrame\n",
    "ts_df = pd.DataFrame({\n",
    "    'time': time,\n",
    "    'temp_obs': temp_obs,\n",
    "    'temp_mod': temp_mod,\n",
    "    'precip_obs': precip_obs,\n",
    "    'precip_mod': precip_mod,\n",
    "    'wind_obs': wind_obs,\n",
    "    'wind_mod': wind_mod\n",
    "})\n",
    "\n",
    print(f\"Generated time series data with {n_time_steps} time steps\")\n",
    print(f\"Variables: Temperature, Precipitation, Wind Speed\")\n",
    "\n",
    # Calculate time-varying metrics\n",
    "def calculate_time_varying_metrics(df, obs_col, mod_col, window=30):\n",
    "    \"\"Calculate rolling window metrics\"\"\"\n",
    "    metrics = pd.DataFrame()\n",
    "    metrics['time'] = df['time']\n",
    "    \n",
    "    # Rolling window calculations\n",
    "    metrics['MAE'] = df[obs_col].rolling(window=window, center=True).apply(\n",
    "        lambda x: ms.MAE(x, df.loc[x.index, mod_col])\n",
    "    )\n",
    "    metrics['RMSE'] = df[obs_col].rolling(window=window, center=True).apply(\n",
    "        lambda x: ms.RMSE(x, df.loc[x.index, mod_col])\n",
    "    )\n",
    "    metrics['Correlation'] = df[obs_col].rolling(window=window, center=True).corr(df[mod_col])\n",
    "    \n",
    "    # Skill scores\n",
    "    metrics['Skill'] = metrics.apply(\n",
    "        lambda row: calculate_rmse_skill(\n",
    "            df.loc[row.name - window//2:row.name + window//2, obs_col],\n",
    "            df.loc[row.name - window//2:row.name + window//2, mod_col]\n",
    "        ) if row.name >= window//2 and row.name < len(df) - window//2 else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for each variable\n",
    "temp_metrics = calculate_time_varying_metrics(ts_df, 'temp_obs', 'temp_mod')\n",
    "precip_metrics = calculate_time_varying_metrics(ts_df, 'precip_obs', 'precip_mod')\n",
    "wind_metrics = calculate_time_varying_metrics(ts_df, 'wind_obs', 'wind_mod')\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "\n",
    # Time series plots\n",
    "axes[0, 0].plot(ts_df['time'], ts_df['temp_obs'], label='Observed', alpha=0.7)\n",
    "axes[0, 0].plot(ts_df['time'], ts_df['temp_mod'], label='Modeled', alpha=0.7)\n",
    "axes[0, 0].set_ylabel('Temperature (°C)')\n",
    "axes[0, 0].set_title('Temperature Time Series')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[1, 0].plot(ts_df['time'], ts_df['precip_obs'], label='Observed', alpha=0.7)\n",
    "axes[1, 0].plot(ts_df['time'], ts_df['precip_mod'], label='Modeled', alpha=0.7)\n",
    "axes[1, 0].set_ylabel('Precipitation')\n",
    "axes[1, 0].set_title('Precipitation Time Series')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[2, 0].plot(ts_df['time'], ts_df['wind_obs'], label='Observed', alpha=0.7)\n",
    "axes[2, 0].plot(ts_df['time'], ts_df['wind_mod'], label='Modeled', alpha=0.7)\n",
    "axes[2, 0].set_ylabel('Wind Speed (m/s)')\n",
    "axes[2, 0].set_title('Wind Speed Time Series')\n",
    "axes[2, 0].legend()\n",
    "axes[2, 0].grid(True, alpha=0.3)\n",
    "axes[2, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    # Rolling metrics\n",
    "axes[0, 1].plot(temp_metrics['time'], temp_metrics['MAE'], label='MAE')\n",
    "axes[0, 1].plot(temp_metrics['time'], temp_metrics['RMSE'], label='RMSE')\n",
    "axes[0, 1].set_ylabel('Error (°C)')\n",
    "axes[0, 1].set_title('Temperature Rolling Metrics (30-day window)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[1, 1].plot(precip_metrics['time'], precip_metrics['MAE'], label='MAE')\n",
    "axes[1, 1].plot(precip_metrics['time'], precip_metrics['RMSE'], label='RMSE')\n",
    "axes[1, 1].set_ylabel('Error')\n",
    "axes[1, 1].set_title('Precipitation Rolling Metrics (30-day window)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[2, 1].plot(wind_metrics['time'], wind_metrics['MAE'], label='MAE')\n",
    "axes[2, 1].plot(wind_metrics['time'], wind_metrics['RMSE'], label='RMSE')\n",
    "axes[2, 1].set_ylabel('Error (m/s)')\n",
    "axes[2, 1].set_title('Wind Speed Rolling Metrics (30-day window)')\n",
    "axes[2, 1].legend()\n",
    "axes[2, 1].grid(True, alpha=0.3)\n",
    "axes[2, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    print(\"\\nTime Series Analysis Summary:\")\n",
    "print(f\"Temperature - Average RMSE: {temp_metrics['RMSE'].mean():.3f}\")\n",
    "print(f\"Precipitation - Average RMSE: {precip_metrics['RMSE'].mean():.3f}\")\n",
    "print(f\"Wind Speed - Average RMSE: {wind_metrics['RMSE'].mean():.3f}\")\n",
    "\n",
    # Seasonal analysis\n",
    "ts_df['month'] = ts_df['time'].dt.month\n",
    "seasonal_performance = ts_df.groupby('month').apply(\n",
    "    lambda x: {\n",
    "        'temp_rmse': ms.RMSE(x['temp_obs'], x['temp_mod']),\n",
    "        'temp_corr': ms.pearson_correlation(x['temp_obs'], x['temp_mod']),\n",
    "        'precip_rmse': ms.RMSE(x['precip_obs'], x['precip_mod']),\n",
    "        'wind_rmse': ms.RMSE(x['wind_obs'], x['wind_mod'])\n",
    "    }\n",
    ").apply(pd.Series)\n",
    "\n",
    print(f\"\\nSeasonal Performance:\")\n",
    print(seasonal_performance.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Integration Dashboard\n",
    "\n",
    "Create a comprehensive dashboard showing all aspects of the integrated analysis."
   ]
  },
 {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive integration dashboard\n",
    "print(\"Comprehensive Integration Dashboard:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Create final dashboard\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Grid layout for subplots\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Performance ranking\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "performance_score_sorted = performance_score.sort_values('composite_score')\n",
    "bars = ax1.barh(range(len(performance_score_sorted)), performance_score_sorted['composite_score'])\n",
    "ax1.set_yticks(range(len(performance_score_sorted)))\n",
    "ax1.set_yticklabels(performance_score_sorted['dataset'])\n",
    "ax1.set_xlabel('Composite Performance Score')\n",
    "ax1.set_title('Overall Performance Ranking')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add color coding based on performance\n",
    "colors = plt.cm.viridis(performance_score_sorted['composite_score'] / performance_score_sorted['composite_score'].max())\n",
    "for bar, color in zip(bars, colors):\n",
    "    bar.set_color(color)\n",
    "\n",
    "# 2. Correlation heatmap\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "corr_data = metrics_df[['Pearson', 'Spearman', 'R2', 'NSE', 'SS']].corr()\n",
    "im2 = ax2.imshow(corr_data, cmap='coolwarm', aspect='auto')\n",
    "ax2.set_xticks(range(len(corr_data.columns)))\n",
    "ax2.set_yticks(range(len(corr_data.columns)))\n",
    "ax2.set_xticklabels(corr_data.columns, rotation=45)\n",
    "ax2.set_yticklabels(corr_data.columns)\n",
    "ax2.set_title('Metric Correlation Heatmap')\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "# 3. Error metrics comparison\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "error_data = metrics_df[['MAE', 'RMSE', 'MBE']].values\n",
    "x3 = np.arange(len(metrics_df))\n",
    "width3 = 0.25\n",
    "\n",
    "for i, metric in enumerate(['MAE', 'RMSE', 'MBE']):\n",
    "    ax3.bar(x3 + i * width3, error_data[:, i], width3, label=metric)\n",
    "\n",
    "ax3.set_xlabel('Dataset')\n",
    "ax3.set_ylabel('Error Value')\n",
    "ax3.set_title('Error Metrics Comparison')\n",
    "ax3.set_xticks(x3 + width3)\n",
    "ax3.set_xticklabels(metrics_df['dataset'], rotation=45)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. PCA results\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "scatter = ax4.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', s=100, alpha=0.7)\n",
    "for i, name in enumerate(dataset_names):\n",
    "    ax4.annotate(name, (X_pca[i, 0], X_pca[i, 1]), xytext=(5, 5), textcoords='offset points')\n",
    "ax4.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "ax4.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "ax4.set_title('PCA of Performance Metrics')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax4)\n",
    "\n",
    "# 5. Feature importance\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "feature_importance = np.abs(pca.components_[0])\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "ax5.bar(range(len(feature_importance)), feature_importance[sorted_idx])\n",
    "ax5.set_xticks(range(len(feature_importance)))\n",
    "ax5.set_xticklabels([feature_names[i] for i in sorted_idx], rotation=45)\n",
    "ax5.set_xlabel('Features')\n",
    "ax5.set_ylabel('Absolute Loading')\n",
    "ax5.set_title('Feature Importance (PC1)')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Time series overview\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "ax6.plot(ts_df['time'][:100], ts_df['temp_obs'][:100], label='Temp Obs', alpha=0.7)\n",
    "ax6.plot(ts_df['time'][:100], ts_df['temp_mod'][:100], label='Temp Mod', alpha=0.7)\n",
    "ax6.plot(ts_df['time'][:100], ts_df['wind_obs'][:100]/10, label='Wind Obs/10', alpha=0.7)\n",
    "ax6.plot(ts_df['time'][:100], ts_df['wind_mod'][:100]/10, label='Wind Mod/10', alpha=0.7)\n",
    "ax6.set_ylabel('Normalized Values')\n",
    "ax6.set_title('Multi-Variable Time Series (First 100 Days)')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 7. Skill scores summary\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "skill_data = metrics_df[['NSE', 'SS']].values\n",
    "x7 = np.arange(len(metrics_df))\n",
    "\n",
    "for i, metric in enumerate(['NSE', 'SS']):\n",
    "    ax7.bar(x7 + i * 0.35, skill_data[:, i], 0.35, label=metric)\n",
    "\n",
    "ax7.set_xlabel('Dataset')\n",
    "ax7.set_ylabel('Skill Score')\n",
    "ax7.set_title('Skill Scores')\n",
    "ax7.set_xticks(x7 + 0.35)\n",
    "ax7.set_xticklabels(metrics_df['dataset'], rotation=45)\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Comprehensive performance radar\n",
    "ax8 = fig.add_subplot(gs[2, 1], projection='polar')\n",
    "categories = ['Error', 'Correlation', 'Skill', 'Efficiency']\n",
    "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)\n",
    "angles = np.concatenate((angles, [angles[0]]))\n",
    "\n",
    "# Calculate composite radar values for the best performing dataset\n",
    "best_idx = performance_score['composite_score'].idxmax()\n",
    "best_dataset = performance_score.loc[best_idx, 'dataset']\n",
    "best_metrics = metrics_df[metrics_df['dataset'] == best_dataset].iloc[0]\n",
    "\n",
    "radar_values = [\n",
    "    1 - best_metrics['RMSE'] / metrics_df['RMSE'].max(),  # Error (inverse)\n",
    "    best_metrics['Pearson'],  # Correlation\n",
    "    best_metrics['NSE'],  # Skill\n",
    "    min(best_metrics['n_samples'] / 1000000, 1)  # Efficiency (normalized)\n",
    "]\n",
    "radar_values.append(radar_values[0])  # Complete the circle\n",
    "\n",
    "ax8.plot(angles, radar_values, 'o-', linewidth=2, label=f'{best_dataset} (Best)')\n",
    "ax8.fill(angles, radar_values, alpha=0.1)\n",
    "ax8.set_xticks(angles[:-1])\n",
    "ax8.set_xticklabels(categories)\n",
    "ax8.set_ylim(0, 1)\n",
    "ax8.set_title(f'Best Performer: {best_dataset}')\n",
    "ax8.legend()\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Final summary text\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "ax9.axis('off')\n",
    "ax9.set_title('Analysis Summary')\n",
    "\n",
    "# Generate summary text\n",
    "summary_text = f\"\"\"Integrated Analysis Summary:\n",
    "\n",
    "Best Performing Dataset: {best_dataset}\n",
    "Composite Score: {performance_score.loc[best_idx, 'composite_score']:.3f}\n",
    "\n",
    "Key Insights:\n",
    "• {metrics_df['dataset'].nunique()} datasets analyzed\n",
    "• {len(feature_names)} features used for ML analysis\n",
    "• {np.sum(clusters == 0)} datasets in Cluster 1\n",
    "• {np.sum(clusters == 1)} datasets in Cluster 2\n",
    "\n",
    "Top Metrics:\n",
    "• Highest Correlation: {metrics_df.loc[metrics_df['Pearson'].idxmax(), 'dataset']} ({metrics_df['Pearson'].max():.3f})\n",
    "• Lowest RMSE: {metrics_df.loc[metrics_df['RMSE'].idxmin(), 'dataset']} ({metrics_df['RMSE'].min():.3f})\n",
    "• Highest NSE: {metrics_df.loc[metrics_df['NSE'].idxmax(), 'dataset']} ({metrics_df['NSE'].max():.3f})\n",
    "\n",
    "Recommendations:\n",
    "• Focus on improving error metrics for lower-performing datasets\n",
    "• Consider ensemble methods to combine model strengths\n",
    "• Continue monitoring temporal patterns for seasonal variations\n",
    "\"\"\"\n",
    "\n",
    "ax9.text(0.05, 0.95, summary_text, transform=ax9.transAxes, fontsize=10,\n",
    "        verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    plt.suptitle('Comprehensive Model Evaluation Dashboard', fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    print(\"\\nIntegration Analysis Complete!\")\n",
    print(\"This dashboard provides a holistic view of model performance across multiple datasets and metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated comprehensive integration examples combining multiple metrics:\n",
    "\n",
    "1. **Multi-Dataset Analysis**: Combined evaluation across temperature, precipitation, wind, and spatial data\n",
    "2. **Performance Comparison**: Radar charts, bar charts, and ranking systems\n",
    "3. **Machine Learning Integration**: PCA, clustering, and feature analysis\n",
    "4. **Time Series Analysis**: Rolling metrics and seasonal pattern detection\n",
    "5. **Comprehensive Dashboard**: Multi-faceted visualization summary\n",
    "\n",
    "These integration techniques provide a complete framework for holistic model evaluation in atmospheric sciences, combining statistical metrics with machine learning insights for comprehensive assessment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
